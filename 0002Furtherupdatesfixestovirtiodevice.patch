From 0dd81505d0cbf9dd40f6ba91ed3859139d931970 Mon Sep 17 00:00:00 2001
From: Peter Dinda <pdinda@northwestern.edu>
Date: Thu, 11 Feb 2016 16:49:27 -0600
Subject: [PATCH 2/2] Further updates / fixes to virtio device

- interaction with device registers
- allocation of ring buffers
---
 include/dev/virtio_pci.h  |  10 +-
 include/dev/virtio_ring.h | 128 +++++++++++++++++++
 src/dev/virtio_pci.c      | 312 +++++++++++++++++++++++++++++++++++++++++++---
 3 files changed, 428 insertions(+), 22 deletions(-)
 create mode 100644 include/dev/virtio_ring.h

diff --git a/include/dev/virtio_pci.h b/include/dev/virtio_pci.h
index 7530c79..45665f8 100644
--- a/include/dev/virtio_pci.h
+++ b/include/dev/virtio_pci.h
@@ -1,17 +1,19 @@
 #ifndef __VIRTIO_PCI
 #define __VIRTIO_PCI
 
-#define MAX_VRINGS 2
+#define MAX_VRINGS 4
 
 enum virtio_pci_dev_type { VIRTIO_PCI_NET, VIRTIO_PCI_BLOCK, VIRTIO_PCI_OTHER };
 
 struct virtio_pci_vring {
   uint64_t size_bytes;
-  uint8_t data[0];
+  uint8_t *data ;
+  uint8_t *aligned_data;
 };
 
 struct virtio_pci_dev {
   enum virtio_pci_dev_type type;
+  char name[32];
 
   // for our linked list of virtio devices
   struct list_head virtio_node;
@@ -29,9 +31,9 @@ struct virtio_pci_dev {
   uint64_t  mem_start;
   uint64_t  mem_end;
 
-  // The number of vrings
+  // The number of vrings in use
   uint8_t num_vrings;
-  struct virtio_pci_dev_vring *vring[2];
+  struct virtio_pci_vring vring[MAX_VRINGS];
 };
 
 int virtio_pci_init(struct naut_info * naut);
diff --git a/include/dev/virtio_ring.h b/include/dev/virtio_ring.h
new file mode 100644
index 0000000..84a4b0a
--- /dev/null
+++ b/include/dev/virtio_ring.h
@@ -0,0 +1,128 @@
+#ifndef VIRTQUEUE_H
+#define VIRTQUEUE_H
+/* An interface for efficient virtio implementation.
+ *
+ * This header is BSD licensed so anyone can use the definitions
+ * to implement compatible drivers/servers.
+ *
+ * Copyright 2007, 2009, IBM Corporation
+ * Copyright 2011, Red Hat, Inc
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of IBM nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL IBM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+#include <stdint.h>
+
+/* This marks a buffer as continuing via the next field. */
+#define VIRTQ_DESC_F_NEXT       1
+/* This marks a buffer as write-only (otherwise read-only). */
+#define VIRTQ_DESC_F_WRITE      2
+/* This means the buffer contains a list of buffer descriptors. */
+#define VIRTQ_DESC_F_INDIRECT   4
+
+/* The device uses this in used->flags to advise the driver: don't kick me
+ * when you add a buffer.  It's unreliable, so it's simply an
+ * optimization. */
+#define VIRTQ_USED_F_NO_NOTIFY  1
+/* The driver uses this in avail->flags to advise the device: don't
+ * interrupt me when you consume a buffer.  It's unreliable, so it's
+ * simply an optimization.  */
+#define VIRTQ_AVAIL_F_NO_INTERRUPT      1
+
+/* Support for indirect descriptors */
+#define VIRTIO_F_INDIRECT_DESC    28
+
+/* Support for avail_event and used_event fields */
+#define VIRTIO_F_EVENT_IDX        29
+
+/* Arbitrary descriptor layouts. */
+#define VIRTIO_F_ANY_LAYOUT       27
+
+// default endianness here is le
+#define le64 uint64_t
+#define le32 uint32_t
+#define le16 uint16_t
+
+
+/* Virtqueue descriptors: 16 bytes.
+ * These can chain together via "next". */
+struct virtq_desc {
+        /* Address (guest-physical). */
+        le64 addr;
+        /* Length. */
+        le32 len;
+        /* The flags as indicated above. */
+        le16 flags;
+        /* We chain unused descriptors via this, too */
+        le16 next;
+} ;
+
+struct virtq_avail {
+        le16 flags;
+        le16 idx;
+        le16 ring[];
+        /* Only if VIRTIO_F_EVENT_IDX: le16 used_event; */
+} ;
+
+/* le32 is used here for ids for padding reasons. */
+struct virtq_used_elem {
+        /* Index of start of used descriptor chain. */
+        le32 id;
+        /* Total length of the descriptor chain which was written to. */
+        le32 len;
+} ;
+
+struct virtq_used {
+        le16 flags;
+        le16 idx;
+        struct virtq_used_elem ring[];
+        /* Only if VIRTIO_F_EVENT_IDX: le16 avail_event; */
+} ;
+
+struct virtq {
+        unsigned int num;
+
+        struct virtq_desc *desc;
+        struct virtq_avail *avail;
+        struct virtq_used *used;
+};
+
+static inline int virtq_need_event(uint16_t event_idx, uint16_t new_idx, uint16_t old_idx)
+{
+         return (uint16_t)(new_idx - event_idx - 1) < (uint16_t)(new_idx - old_idx);
+}
+
+/* Get location of event indices (only with VIRTIO_F_EVENT_IDX) */
+static inline le16 *virtq_used_event(struct virtq *vq)
+{
+        /* For backwards compat, used event index is at *end* of avail ring. */
+        return &vq->avail->ring[vq->num];
+}
+
+static inline le16 *virtq_avail_event(struct virtq *vq)
+{
+        /* For backwards compat, avail event index is at *end* of used ring. */
+        return (le16 *)&vq->used->ring[vq->num];
+}
+#endif /* VIRTQUEUE_H */
diff --git a/src/dev/virtio_pci.c b/src/dev/virtio_pci.c
index 9217da7..02d283d 100644
--- a/src/dev/virtio_pci.c
+++ b/src/dev/virtio_pci.c
@@ -1,26 +1,142 @@
 #include <nautilus/nautilus.h>
 #include <dev/pci.h>
 #include <dev/virtio_pci.h>
+#include <dev/virtio_ring.h>
 
 #ifndef NAUT_CONFIG_DEBUG_VIRTIO_PCI
 #undef DEBUG_PRINT
 #define DEBUG_PRINT(fmt, args...)
-#endif 
+#endif
+
+// set to 1 to use memory mapped regs
+// set to 0 to use ioport mapped regs
+// leave at 0 for time being...
+#define ACCESS_VIA_MEM 0
 
 #define INFO(fmt, args...) printk("VIRTIO_PCI: " fmt, ##args)
 #define DEBUG(fmt, args...) DEBUG_PRINT("VIRTIO_PCI: DEBUG: " fmt, ##args)
 #define ERROR(fmt, args...) printk("VIRTIO_PCI: ERROR: " fmt, ##args)
 
-// list of virtio devices
+// list of virtio devices we are managing
 static struct list_head dev_list;
 
+// common register offsets
+#define DEVICE_FEATURES 0x0    // 4 byte
+#define GUEST_FEATURES  0x4    // 4 byte
+#define QUEUE_ADDR      0x8    // 4 byte
+#define QUEUE_SIZE      0xc    // 2 byte
+#define QUEUE_SEL       0xe    // 2 byte
+#define QUEUE_NOTIFY    0x10   // 2 byte
+#define DEVICE_STATUS   0x12   // 1 byte
+#define ISR_STATUS      0x13   // 1 byte
+#define CONFIG_VEC      0x14   // 2 byte
+#define QUEUE_VEC       0x16   // 2 byte
+
+inline static uint32_t read_regl(struct virtio_pci_dev *dev, uint32_t offset)
+{
+  uint32_t result;
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single read
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  //  DEBUG("addr=%p\n",addr);
+  __asm__ __volatile__ ("movl (%1),%0"
+			: "=r"(result)
+			: "r"(addr)
+			: "memory");
+  return result;
+#else
+  return inl(dev->ioport_start+offset);
+#endif
+}
+
 
-int virtio_pci_init(struct naut_info * naut)
+inline static void write_regl(struct virtio_pci_dev *dev, uint32_t offset, uint32_t data)
+{
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single write
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  __asm__ __volatile__ ("movl %1, (%0)"
+			: "=r"(addr)
+			: "r"(data)
+			: "memory");
+#else
+  outl(data,dev->ioport_start+offset);
+#endif
+}
+
+uint32_t read_regw(struct virtio_pci_dev *dev, uint32_t offset)
+{
+  uint16_t result;
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single read
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  __asm__ __volatile__ ("movw (%1),%0"
+			: "=r"(result)
+			: "r"(addr)
+			: "memory");
+  return result;
+#else
+  return inw(dev->ioport_start+offset);
+#endif
+}
+
+inline static void write_regw(struct virtio_pci_dev *dev, uint32_t offset, uint16_t data)
+{
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single write
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  __asm__ __volatile__ ("movw %1, (%0)"
+			: "=r"(addr)
+			: "r"(data)
+			: "memory");
+#else
+  outw(data,dev->ioport_start+offset);
+#endif
+}
+
+inline static uint32_t read_regb(struct virtio_pci_dev *dev, uint32_t offset)
+{
+  uint8_t result;
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single read
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  __asm__ __volatile__ ("movb (%1),%0"
+			: "=r"(result)
+			: "r"(addr)
+			: "memory");
+  return result;
+#else
+  return inb(dev->ioport_start+offset);
+#endif
+}
+
+inline static void write_regb(struct virtio_pci_dev *dev, uint32_t offset, uint8_t data)
+{
+#if ACCESS_VIA_MEM
+  // we want to be assured that we are doing a single write
+  // without any compiler nonsense
+  uint64_t addr = dev->mem_start + offset;
+  __asm__ __volatile__ ("movb %1, (%0)"
+			: "=r"(addr)
+			: "r"(data)
+			: "memory");
+#else
+  outb(data,dev->ioport_start+offset);
+#endif
+}
+
+
+static int discover_devices(struct pci_info *pci)
 {
-  struct pci_info *pci = naut->sys.pci;
   struct list_head *curbus, *curdev;
+  int num=0;
 
-  INFO("init\n");
+  DEBUG("Discovering and naming virtio devices\n");
 
   INIT_LIST_HEAD(&dev_list);
 
@@ -29,8 +145,6 @@ int virtio_pci_init(struct naut_info * naut)
     return -1;
   }
 
-  DEBUG("Finding virtio devices\n");
-
   list_for_each(curbus,&(pci->bus_list)) { 
     struct pci_bus *bus = list_entry(curbus,struct pci_bus,bus_node);
 
@@ -42,8 +156,8 @@ int virtio_pci_init(struct naut_info * naut)
 
       DEBUG("Device %u is a %x:%x\n", pdev->num, cfg->vendor_id, cfg->device_id);
 
-      if (cfg->vendor_id==0x1af4) {
-	DEBUG("Virtio Device Found\n");
+      if (cfg->vendor_id==0x1af4 && cfg->device_id>=0x1000 && cfg->device_id<=0x103f) {
+	DEBUG("Virtio Device Found (subsys_id=0x%x)\n",cfg->dev_cfg.subsys_id);
 	struct virtio_pci_dev *vdev;
 
 	vdev = malloc(sizeof(struct virtio_pci_dev));
@@ -56,12 +170,12 @@ int virtio_pci_init(struct naut_info * naut)
 	
 	vdev->pci_dev = pdev;
 
-	switch (cfg->device_id) { 
-	case 0x1000:
+	switch (cfg->dev_cfg.subsys_id) { 
+	case 0x1:
 	  DEBUG("Net Device\n");
 	  vdev->type = VIRTIO_PCI_NET;
 	  break;
-	case 0x1001:
+	case 0x2:
 	  DEBUG("Block Device\n");
 	  vdev->type = VIRTIO_PCI_BLOCK;
 	  break;
@@ -71,6 +185,12 @@ int virtio_pci_init(struct naut_info * naut)
 	  break;
 	}
 
+	snprintf(vdev->name,32, "virtio-%d-%s", num, 
+		 vdev->type==VIRTIO_PCI_NET ? "net" :
+		 vdev->type==VIRTIO_PCI_BLOCK ? "block" :
+		 vdev->type==VIRTIO_PCI_OTHER ? "other" : "UNKNOWN");
+
+
 	// PCI Interrupt (A..D)
 	vdev->pci_intr = cfg->dev_cfg.intr_pin;
 	// Figure out mapping here or look at capabilities for MSI-X
@@ -86,7 +206,8 @@ int virtio_pci_init(struct naut_info * naut)
 	  if (i>=2 && bar!=0) { 
 	    DEBUG("Not expecting this to be a non-empty bar...\n");
 	  }
-	  if (!(bar & 0x0)) { 
+	  if (!(bar & 0x1)) { 
+	    // handle only 32 bit memory for now
 	    uint8_t mem_bar_type = (bar & 0x6) >> 1;
 	    if (mem_bar_type != 0) { 
 	      ERROR("Cannot handle memory bar type 0x%x\n", mem_bar_type);
@@ -134,23 +255,178 @@ int virtio_pci_init(struct naut_info * naut)
 
 	}
 
-	INFO("Adding virtio %s device: bus=%u dev=%u func=%u: pci_intr=%u intr_vec=%u ioport_start=%p ioport_end=%p mem_start=%p mem_end=%p\n",
+	INFO("Adding virtio %s device with name %s : bus=%u dev=%u func=%u: pci_intr=%u intr_vec=%u ioport_start=%p ioport_end=%p mem_start=%p mem_end=%p\n",
 	     vdev->type==VIRTIO_PCI_BLOCK ? "block" :
 	     vdev->type==VIRTIO_PCI_NET ? "net" : "other",
+	     vdev->name,
 	     bus->num, pdev->num, 0,
 	     vdev->pci_intr, vdev->intr_vec,
 	     vdev->ioport_start, vdev->ioport_end,
 	     vdev->mem_start, vdev->mem_end);
 	     
 
-	list_add(&vdev->virtio_node,&dev_list);
-	//	list_add(&dev_list, &vdev->virtio_node);
+	list_add_tail(&vdev->virtio_node,&dev_list);
+	num++;
+
       }
-      
     }
   }
-      
+  return 0;
+}
+
+
+#define ALIGN(x) (((x) + 4095UL) & ~4095UL) 
+
+#define NUM_PAGES(x) ((x)/4096 + !!((x)%4096))
+
+
+static inline unsigned compute_size(unsigned int qsz) 
+{ 
+     return ALIGN(sizeof(struct virtq_desc)*qsz + sizeof(uint16_t)*(3 + qsz)) 
+          + ALIGN(sizeof(uint16_t)*3 + sizeof(struct virtq_used_elem)*qsz); 
+}
+
+int virtio_ring_init(struct virtio_pci_dev *dev)
+{
+  uint16_t i;
+  uint64_t size;
+  uint64_t alloc_size;
+  
+
+  DEBUG("Ring init of %s\n",dev->name);
+
+  // now let's figure out the ring sizes
+  dev->num_vrings=0;
+  for (i=0;i<MAX_VRINGS;i++) {
+    write_regw(dev,QUEUE_SEL,i);
+    size = read_regw(dev,QUEUE_SIZE);
+    if (size==0) {
+      // out of queues to support
+      break;
+    }
+    INFO("Ring %u has uncooked size 0x%lx\n", i, size);
+    size = compute_size(size);
+    INFO("Ring %u has cooked size 0x%lx bytes\n", i, size);
+
+
+    dev->vring[i].size_bytes = size;
+    alloc_size = 4096 * (NUM_PAGES(size) + 1);
+
+    if (!(dev->vring[i].data = malloc(alloc_size))) {
+      ERROR("Cannot allocate ring\n");
+      return -1;
+    }
+
+    memset(dev->vring[i].data,0,alloc_size);
+
+    dev->vring[i].aligned_data = (uint8_t *)ALIGN((uint64_t)(dev->vring[i].data));
+    
+    // now tell device about the ring
+    // note it's a 32 bit register, but the address is a page address
+    // so it really represents a 44 bit address (32 bits * 4096)
+    write_regl(dev,QUEUE_ADDR,(uint32_t)(((uint64_t)(dev->vring[i].aligned_data))/4096));
+
+    dev->num_vrings++;
+  }
+
+  if (i==MAX_VRINGS) { 
+    ERROR("Device needs to many rings\n");
+    return -1;
+  }
+    
+  return 0;
+}
+
+static int virtio_block_init(struct virtio_pci_dev *dev)
+{
+
+  uint32_t val;
+
+  DEBUG("Block init of %s\n",dev->name);
+
+  write_regb(dev,DEVICE_STATUS,0x0); // driver resets device
+  write_regb(dev,DEVICE_STATUS,0b1); // driver acknowledges device
+  write_regb(dev,DEVICE_STATUS,0b11); // driver can drive device
+
+  val = read_regl(dev,DEVICE_FEATURES);
+  DEBUG("device features: 0x%0x\n",val);
+
+
+
+  return 0;
+}
+
+static int virtio_net_init(struct virtio_pci_dev *dev)
+{
+  uint32_t val;
+
+  DEBUG("Net init of %s\n",dev->name);
+
+  write_regb(dev,DEVICE_STATUS,0x0); // driver resets device
+  write_regb(dev,DEVICE_STATUS,0b1); // driver acknowledges device
+  write_regb(dev,DEVICE_STATUS,0b11); // driver can drive device
+
+  val = read_regl(dev,DEVICE_FEATURES);
+  DEBUG("device features: 0x%0x\n",val);
+
+  return 0;
+}
+
+static int bringup_device(struct virtio_pci_dev *dev)
+{
+  DEBUG("Bringing up %s\n",dev->name);
+  switch (dev->type) {
+  case VIRTIO_PCI_BLOCK:
+    if (virtio_ring_init(dev)) { 
+      ERROR("Failed to bring up device %s\n", dev->name);
+      return -1;
+    }
+    return virtio_block_init(dev);
+    break;
+  case VIRTIO_PCI_NET:
+    if (virtio_ring_init(dev)) { 
+      ERROR("Failed to bring up device %s\n", dev->name);
+      return -1;
+    }
+    return virtio_net_init(dev);
+    break;
+  case VIRTIO_PCI_OTHER:
+  default:
+    INFO("Skipping unsupported device type\n");
+    return 0;
+  }
+    
+}
+
+static int bringup_devices()
+{
+  struct list_head *curdev;
+
+  DEBUG("Bringing up virtio devices\n");
+
+  list_for_each(curdev,&(dev_list)) { 
+    struct virtio_pci_dev *dev = list_entry(curdev,struct virtio_pci_dev,virtio_node);
+    if (bringup_device(dev)) { 
+      ERROR("Bringup of virtio devices failed\n");
+      return -1;
+    }
+  }
+
+  return 0;
+}
+
+int virtio_pci_init(struct naut_info * naut)
+{
+
+  INFO("init\n");
+
+  if (discover_devices(naut->sys.pci)) { 
+    ERROR("Discovery failed\n");
+    return -1;
+  }
+
 
+  bringup_devices();
   
   return 0;
 }
-- 
1.9.1

